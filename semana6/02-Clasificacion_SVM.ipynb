{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploración de las SVMs\n",
    "\n",
    "**NOTA: Para este ejercicio estamos más interesados en explorar el algoritmo.  Por lo tanto nos saltearemos las partes de normalización y de división de los datos en entrenamiento/prueba.  Esto nos permitirá poner más atención en cómo pueden cambiar los parámetros cambiar un SVM**\n",
    "\n",
    "[Enlace a un excelente artículo sobre SVM](http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=4448154647BC7B10C991CEF2236BBA38?doi=10.1.1.114.4288&rep=rep1&type=pdf)\n",
    "* A tutorial on support vector regression by ALEX J. SMOLA and BERNHARD SCHOLKOPF\n",
    "\n",
    "## SVM - Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos\n",
    "\n",
    "Los datos que se utilizarán simulan una investigación en medicina en la que ratones infectados con un virus fueron tratados con varias dosis de dos medicinas y luego examinados dos semanas más tarde para ver si aún seguían infectados. Con estos datos, el objetivo es crear un modelo de clasificación que pueda predecir (dadas dos medidas de dosis) si el ratón seguirá infectado con el virus. \n",
    "\n",
    "Podrán darse cuenta que los grupos son muy \"separables\", esto es a propósito, para explorar el comportamiento de los varios parámetros de un modelo SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv(\"mouse_viral_study.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'Med_1_mL', y = 'Med_2_mL', hue = 'Virus Present',\n",
    "                data = datos, palette = 'seismic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Hiperplano de separación\n",
    "\n",
    "El objetivo con SVM es la creación del hiperplano que mejor logre separar las categorías.  En 2 dimensiones esto es simplemente una línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'Med_1_mL', y = 'Med_2_mL', hue = 'Virus Present', \n",
    "                palette = 'seismic', data = datos)\n",
    "\n",
    "# De alguna forma se quiere que mágicamente se cree una línea de separación ( una línea en 2D)\n",
    "\n",
    "x = np.linspace(0, 10, 100)\n",
    "m = -1\n",
    "b = 11\n",
    "y = m * x + b\n",
    "plt.plot(x, y, 'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # Supprt Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA: Parar este ejemplo, se explorará el algoritmo, por lo tanto no se hará normalización ni división de datos entrenamiento/prueba**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = datos['Virus Present']\n",
    "X = datos.drop('Virus Present', axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = SVC(kernel = 'linear', C = 1000)\n",
    "modelo.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta importación viene de un módulo externo .py\n",
    "# https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html\n",
    "from svm_margin_plot import plot_svm_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svm_boundary(modelo, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiper Parámetros\n",
    "\n",
    "### C\n",
    "\n",
    "Parámetro de regularization. La potencia de la regurlarización es **inversamente** proporcional a C. Debe ser estrictamente positivo. La penalización es de l2 cuadrado.\n",
    "\n",
    "*Nota: Si está más interesado en el desarrollo matemático, el valor de C como se describre en  ISLR, C en scikit-learn ss **inversamente** proporcional a este valor.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = SVC(kernel = 'linear', C = 0.05)\n",
    "modelo.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svm_boundary(modelo, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel\n",
    "\n",
    "[Selección de un \"Kernel\"](https://stats.stackexchange.com/questions/18030/how-to-select-kernel-for-svm?rq=1)\n",
    "\n",
    "#### rbf - [Radial Basis Function](https://en.wikipedia.org/wiki/Radial_basis_function_kernel)\n",
    "\n",
    "\n",
    "Cuando se entrena una SVM con Radial Basis Function (RBF) kernel, es necesario considerar dos parámetros: C y gamma. El parámetro C, común a todos los kernels SVM, da un balance (trades off) la mala clasificación de los ejemplos de entrenamientocontra la simplicidad de la superficie de decisión. Un valor bajo de C hace que la superficie de decisión sea lisasurface, un valor alto de C busca classificar todas las observaciones de entrenamiento correctamente. gamma define qué tanta influence tiene una solo observación de entrenamieto. Entre más alto sea gamma, más cerca deben estar las otras muestras para que sean afectadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = SVC(kernel = 'rbf', C = 1)\n",
    "modelo.fit(X, y)\n",
    "plot_svm_boundary(modelo, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = SVC(kernel = 'sigmoid')\n",
    "modelo.fit(X, y)\n",
    "plot_svm_boundary(modelo, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grado (Degree) (sólo para kernels poly)\n",
    "\n",
    "El grado (Degree) de la función polinomial del kernel ('poly').\n",
    "Este parámetro es ignorado por todos los demás modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = SVC(kernel = 'poly', C = 1, degree = 1)\n",
    "modelo.fit(X, y)\n",
    "plot_svm_boundary(modelo, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = SVC(kernel = 'poly', C = 1, degree = 2)\n",
    "modelo.fit(X, y)\n",
    "plot_svm_boundary(modelo, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gamma\n",
    "\n",
    "gamma : {'scale', 'auto'} o float, default='scale'\n",
    "    Coeficient de Kernel para 'rbf', 'poly' y 'sigmoid'.\n",
    "\n",
    "    - si ``gamma = 'scale'`` (default) es pasado cuando utiliza\n",
    "      1 / (n_features * X.var()) como valor de gamma,\n",
    "    - si 'auto', utiliza 1 / n_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = SVC(kernel = 'rbf', C = 1, gamma = 0.01)\n",
    "modelo.fit(X, y)\n",
    "plot_svm_boundary(modelo, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda por malla (Grid Search)\n",
    "\n",
    "Hay que tener en mente que, para este ejemplo simple, las categorías fueron fácilmente separadas. Esto quiere decir que cada variación de modelo podría fácilmente llegar a una exactitud de 100%.  Por lo tanto el significado de una búsqueda por malla no tiene sentido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "malla_parametros = {'C':[0.01, 0.1, 1],'kernel':['linear', 'rbf']}\n",
    "malla = GridSearchCV(svm, malla_parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota:  de nuevo no se usó Train|Test\n",
    "malla.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exactitud de 100% (como se esperaba)\n",
    "malla.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malla.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, este ejercicio fue más para ver el proceso de búsqueda por malla.  Recuerde que en una situación real, sí deben realizar una división entreno/prueba y obtener métricas finales de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
